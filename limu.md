# 预备知识
## 数据操作
在PyTorch中,当使用torch.cat()函数进行张量拼接时, dim参数确定了沿着哪个维度进行拼接,以下是
参数的详细解释：
1. dim=0 （第一个维度）：
会在每个张量的第一个维度上进行拼接，
对于3D张量而言，这个维度指的是张量的“块”数量。
示例:如果有两个3×3×4形状的张量,通过在 dim-e 拼接会得到一个6×3×4的张量,x
2. dim=1 （第二个维度）：
会在每个张量的第二个维度上进行拼接。
对于3D张量而言，这个维度指的是每个“块”中的行数。
示例:如果有两个3x3×4形状的张量,通过在dim-1 拼接会得到一个3×6×4的张量,x
3. dim=-1 或 dim=2 (第三个维度):
会在每个张量的第三个维度上进行拼接,
对于3D张量而言，这个维度指的是每一行中的列数。
示例：如果有两个3× 3× 4形状的张量，通过在 dim--1 或 dim-2 拼接会得到一个3 ×3× 8 的张量。

在PyTorch中，使用 x += Y 确实能够减少操作的内存开销。原因如下：
1. 就地操作：
X += Y 是一个就地操作（in-place operation），它不创建新的张量，而是在原地直接修改 x 的值
这减少了内存分配和复制的开销，因为没有创建新的张量来存储结果。
2.内存效率：
就地操作避免了分配新内存和可能的内存复制操作，因此在处理大张量时，可以显著降低内存使用量。
3. 性能优化：
由于减少了内存分配和复制操作，使用就地操作通常会带来性能提升，尽管这可能是微小的优化。

.item() 方法只能在包含单个元素的张量上使用，如果你想要将整个张量转换成一个 Python 列表，你应该使用 .tolist() 方法
## 线性代数
- 矩阵的转置：A.T
- 方阵：行数等于列数。对称方阵：A=A.T
- A * B：两个矩阵的按元素乘法称为Hadamard积（Hadamard product）（数学符号![image](https://github.com/TFSN20/code/assets/64345882/10ec13ad-809a-4ef1-854d-1287a2b01371)）
- axis：A.sum(axis=1)，对于二维4X3矩阵，指定axis=1将通过汇总所有列的元素降维（轴1，行元素相加）。因此，输入轴1的维数在输出形状中消失，得到1X4矩阵。
